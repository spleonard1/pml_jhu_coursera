---
title: "PML Course Project- Leonard"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Setup
I'll load the tidyverse and caret packages to make it easier top work with the sample data, and read that data in.

```{r prepare}
library(tidyverse)
library(caret)

train_data <- read_csv("pml-training.csv")
```

## Explore data
What does the data look like? I plan to use a random forest for this prediction, so I'll need to remove any columns that contain "NA" values.


```{r explore}

glimpse(train_data)
```

Oh no! so many NA columns. I'm going to use the "tidyimpute" package to make it easy to remove those columns. This code will take the training data and remove any columns with "na" values. I then remove by hand columns that contain character values or things that obviously wont help prediction, like "user_name"

```{r clean}
library(tidyimpute)
train_data %>% 
  drop_cols_any_na() %>%
  select(-X1,
         -user_name,
         -raw_timestamp_part_1,
         -raw_timestamp_part_2,
         -cvtd_timestamp,
         -new_window)-> clean_data

```

## Train a model
Using the "clean_data" I will extract the predictors and fit a random forest using the caret package. I use a pca preprocess, and use repeated cross-validation to minimize out of sample error. I do some multiprocessing to speed things up. 

```{r train, cache=TRUE}
predictors <- clean_data %>% select(-classe)
predicted <- clean_data %>% select(classe)

#train control parameters
ctrl <- trainControl(method = "repeatedcv",
                     repeats = 5,
                     number = 10)
#and use parallel processng to speed things up
library(doParallel)
cl <- makePSOCKcluster(5)
registerDoParallel(cl)

rf_model <- train(data.frame(predictors), 
                  predicted$classe, 
                  method = "rf", 
                  preProcess = "pca",
                  trControl = ctrl)
rf_model
```

## Evaluate the model
The model looks good.

## Predict the test set
Now I use the rf_model to predict on the test set. I will read in and process the test data identically to the train data.

```{r predict}
test_data <- read_csv("pml-testing.csv")
test_data %>% 
  drop_cols_any_na() %>%
  select(-X1,
         -user_name,
         -raw_timestamp_part_1,
         -raw_timestamp_part_2,
         -cvtd_timestamp,
         -new_window)-> clean_test

predict(rf_model, newdata = clean_test)
```

## How did we do?

```{r}
#inspect the model
rf_model

```
Based on Accuracy reported, the model `mtry=2` performs best. The high accuracy on this data (~0.983) bodes well for the model, but may be an underestimate compared to test data. The real proof is in the test_data pudding...

I hope I pass the quiz!